# -*- coding: utf-8 -*-
"""VADER_WORDCLOUD_ANALYSIS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gQJxIMbcpDTEM5xVDoNPO1t2ozUQuhjK

IMPRTING LIBRARIES AND DATA FILE
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk 
nltk.download("vader_lexicon")

df = pd.read_csv("/content/movie.csv")
df = df.drop(columns ='label')
print(df[:10])

"""ANALYZING THE SENTIMENTS """

sid = SentimentIntensityAnalyzer()
rankings= []
for i in df['text']:
    score=sid.polarity_scores(i)
    scores = score["compound"]
    rounded_scores = round(scores*10,2)
    rankings.append(rounded_scores)

df['rankings']=rankings

print(df)

"""TOTAL POSTIVE AND NEGATIVE WORDS"""

pos_count = len(df[df["rankings"] > 0])
neg_count = len(df[df["rankings"] < 0])

pos_count, neg_count

"""WORDCLOUD PROCESSING THE KEY WORDS USED """

from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator
import pandas as pd
import matplotlib.pylab as plt
from PIL import Image
import numpy as np

stopwords = set(STOPWORDS)
mask = np.array(Image.open('/content/vader_image.png'))

#wordcloud
wordcloud = WordCloud(stopwords = stopwords , width=1600 , height=800,mask=mask,background_color="White",colormap="Set2").generate(''.join(df['text']))
plt.figure(figsize=(20,10),facecolor='k')
plt.imshow(wordcloud,interpolation='bilinear')
plt.axis('off')
plt.tight_layout (pad=0)

#saving the image of wordcloud

plt.show()

"""CLASSIFYING NEGATIVE WORDS AND POSTIVE WORDS """

# Create a new data frame "reviews" to perform exploratory data analysis upon that
reviews = df
# Dropping null values
reviews.dropna(inplace=True)
score_1 = reviews[reviews['rankings'] >= 5]
score_2 = reviews[reviews['rankings'] >= 0]
# score_3 = reviews[reviews['rankings'] == 0]
score_4 = reviews[reviews['rankings'] <= -1]
score_5 = reviews[reviews['rankings'] <= -5]
reviews_sample = pd.concat([score_1,score_2,score_4,score_5],axis=0)
reviews_sample.reset_index(drop=True,inplace=True)

reviews_str = reviews_sample.text.str.cat()

# Now let's split the data into Negative (Score is 1 or 2) and Positive (4 or 5) Reviews.
negative_reviews = reviews_sample[reviews_sample['rankings'].isin([-1,-5]) ]
positive_reviews = reviews_sample[reviews_sample['rankings'].isin([5,0]) ]
# Transform to single string
negative_reviews_str = negative_reviews.text.str.cat()
positive_reviews_str = positive_reviews.text.str.cat()

wordcloud_negative = WordCloud(background_color='white').generate(negative_reviews_str)
wordcloud_positive = WordCloud(background_color='black').generate(positive_reviews_str)
# Plot
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(211)
ax1.imshow(wordcloud_negative,interpolation='bilinear')
ax1.axis("off")
ax1.set_title('Reviews with Negative Scores',fontsize=20)

fig = plt.figure(figsize=(10,10))
ax2 = fig.add_subplot(212)
ax2.imshow(wordcloud_positive,interpolation='bilinear')
ax2.axis("off")
ax2.set_title('Reviews with Positive Scores',fontsize=20)
plt.show()

negative_reviews_str

"""Cleaning the Data

Removing Punctuations
"""

import re
def clean(text):
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub(r'\s+', ' ', text, flags=re.I)
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text = re.sub('<.*?>+', '', text)
    return text

reviews['text']= reviews['text'].apply(lambda x: clean(x))

reviews

"""Lower Casing"""

clean_data1 = reviews["text"].str.lower()
print(clean_data1)

clean_data1

"""Removing Stopwords"""

from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')

clean_data2 = [word for word in clean_data1 if not word in stopwords.words()]
print(clean_data1)

"""Lemmatization"""

from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()
review_data= [lemmatizer.lemmatize(t) for t in clean_data2]

review_data